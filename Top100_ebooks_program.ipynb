{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Top 100 eBooks from Gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the necessary libraries, including regex and beautifulsoup.\n",
    "2. Check the SSL certificate.\n",
    "3. Read the HTML from the URL.\n",
    "4. Write a small function to check the status of the web request.\n",
    "5. Decode the response and pass this on to BeautifulSoup for HTML parsing.\n",
    "6. Find all the href tags and store them in the list of links. Check what the list looks like – print the first 30 elements.\n",
    "7. Use a regular expression to find the numeric digits in these links. These are the file numbers for the top  \n",
    "   100 eBooks.\n",
    "8. Initialize the empty list to hold the file numbers over an appropriate range and use regex to find the \n",
    "   numeric digits in the link href string. Use the findall method.\n",
    "9. What does the soup object's text look like? Use the .text method and print only the first 2,000 characters \n",
    "   (do not print the whole thing, as it is too long).\n",
    "10. Search in the extracted text (using a regular expression) from the soup object to find the names of the top     100 eBooks (yesterday's ranking).\n",
    "11. Create a starting index. It should point at the text Top 100 Ebooks yesterday. Use the splitlines method of     soup.text. It splits the lines of text of the soup object.\n",
    "12. Loop 1-100 to add the strings of the next 100 lines to this temporary list. Hint: use the splitlines method.\n",
    "13. Use a regular expression to extract only text from the name strings and append it to an empty list. Use  \n",
    "    match and span to find the indices and use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries, including regex and beautifulsoup.\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the HTML from the URL and pass on to BeautifulSoup\n",
    "top100url = 'https://www.gutenberg.org/browse/scores/top'\n",
    "response = requests.get(top100url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a small function to check the status of web request\n",
    "def status_check(r):\n",
    "    if r.status_code==200:\n",
    "        print(\"Success!\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Failed!\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_check(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the response and pass on to BeautifulSoup for HTML parsing\n",
    "\n",
    "contents = response.content.decode(response.encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to hold all the http links in the HTML page\n",
    "lst_links=[]\n",
    "\n",
    "# Find all the href tags and store them in the list of links\n",
    "for link in soup.find_all('a'):\n",
    "    #print(link.get('href'))\n",
    "    lst_links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/about/',\n",
       " '/about/',\n",
       " '/policy/collection_development.html',\n",
       " '/about/contact_information.html',\n",
       " '/about/background/',\n",
       " '/policy/permission.html',\n",
       " '/policy/privacy_policy.html',\n",
       " '/policy/terms_of_use.html',\n",
       " '/ebooks/',\n",
       " '/ebooks/',\n",
       " '/ebooks/bookshelf/',\n",
       " '/browse/scores/top',\n",
       " '/ebooks/offline_catalogs.html',\n",
       " '/help/',\n",
       " '/help/',\n",
       " '/help/copyright.html',\n",
       " '/help/errata.html',\n",
       " '/help/file_formats.html',\n",
       " '/help/faq.html',\n",
       " '/policy/',\n",
       " '/help/public_domain_ebook_submission.html',\n",
       " '/help/submitting_your_own_work.html',\n",
       " '/help/mobile.html',\n",
       " '/attic/',\n",
       " '/donate/',\n",
       " '/donate/',\n",
       " '#books-last1',\n",
       " '#authors-last1',\n",
       " '#books-last7']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first 30 rows\n",
    "\n",
    "lst_links[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regular expression to find the numeric digits in these links.These are the file number for the Top 100 books.\n",
    "\n",
    "#Initialize empty list to hold the file numbers\n",
    "\n",
    "booknum=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop the selected range from num 19 to 119 from the link list\n",
    "for i in range(19,119):\n",
    "    link=lst_links[i]\n",
    "    link=link.strip()\n",
    "    # Regular expression to find the numeric digits in the link (href) string\n",
    "    n=re.findall('[0-9]+',link)\n",
    "    if len(n)==1:\n",
    "        # Append the filenumber casted as integer\n",
    "        booknum.append(int(n[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The file numbers for the top 100 ebooks on Gutenberg are shown below\n",
      "----------------------------------------------------------------------\n",
      "[1, 1, 7, 7, 30, 30, 1513, 2641, 145, 37106, 16389, 2701, 67979, 100, 394, 6761, 2160, 4085, 6593, 5197, 1259, 84, 1342, 17607, 70055, 11, 64317, 174, 98, 68891, 1952, 2542, 70052, 28054, 844, 1080, 76, 1661, 345, 5200, 2554, 408, 4300, 2591, 1260, 42108, 205, 1400, 1232, 46, 25344, 6130, 70051, 5827, 43, 219, 20228, 67098, 2600, 1184, 74, 70056, 36, 30254, 70054, 768, 20203, 3206, 2814, 45, 70049, 730, 158, 996, 37134, 1497, 23, 120, 1727, 514, 4363, 16328, 15399, 5740, 161, 58585, 55, 1399, 829, 47629, 70048, 3207]\n"
     ]
    }
   ],
   "source": [
    "# Print the numbers\n",
    "print (\"\\nThe file numbers for the top 100 ebooks on Gutenberg are shown below\\n\"+\"-\"*70)\n",
    "print(booknum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 100 | Project Gutenberg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Menu▾\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "          ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "About Project Gutenberg\n",
      "Collection Development\n",
      "Contact Us\n",
      "History & Philosophy\n",
      "Permissions & License\n",
      "Privacy Policy\n",
      "Terms of Use\n",
      "\n",
      "\n",
      "\n",
      "Search and Browse\n",
      "      \t  ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "Book Search\n",
      "Bookshelves\n",
      "Frequently Downloaded\n",
      "Offline Catalogs\n",
      "\n",
      "\n",
      "\n",
      "Help\n",
      "          ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "All help topics →\n",
      "Copyright Procedures\n",
      "Errata, Fixes and Bug Reports\n",
      "File Formats\n",
      "Frequently Asked Questions\n",
      "Policies →\n",
      "Public Domain eBook Submission\n",
      "Submitting Your Own Work\n",
      "Tablets, Phones and eReaders\n",
      "The Attic →\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Frequently Viewed or Downloaded\n",
      "These listings are based on the number of times each eBook gets downloaded.\n",
      "      Multiple downloads from the same Internet address on the same day count as one download, and addresses that download more than 100 eBooks in a day are considered robots and are not counted.\n",
      "\n",
      "Downloaded Books\n",
      "2023-02-17255824\n",
      "last 7 days1847060\n",
      "last 30 days8050233\n",
      "\n",
      "\n",
      "\n",
      "Top 100 EBooks yesterday\n",
      "Top 100 Authors yesterday\n",
      "Top 100 EBooks last 7 days\n",
      "Top 100 Authors last 7 days\n",
      "Top 100 EBooks last 30 days\n",
      "Top 100 Authors last 30 days\n",
      "\n",
      "\n",
      "Top 100 EBooks yesterday\n",
      "\n",
      "Romeo and Juliet by William Shakespeare (6472)\n",
      "A Room with a View by E. M.  Forster (5652)\n",
      "Middlemarch by George Eliot (5551)\n",
      "Little Women; Or, Meg, Jo, Beth, and Amy by Louisa May Alcott (5200)\n",
      "The Enchanted April by Elizabeth Von Arnim (5114)\n",
      "Moby Dick; Or, The Whale by Herman Melville (5098)\n",
      "The Blue Castle: a novel by L. M.  Montgomery (5013)\n",
      "The Complete Works of William Shakespeare by William Shakespeare (4979)\n",
      "Cranford by Elizabeth Cleghorn Gaskell (4844)\n",
      "The Adventures of Ferdinand Count Fathom — Complete by T.  Smollett (4815)\n",
      "The Expedition of Humphry Clinker by T.  Smollett (4737)\n",
      "The Adventures of Roderick Random by T.  Smollett (4691)\n",
      "History of Tom Jones, a Foundling by Henry Fielding (4501)\n",
      "My Life — Volume 1 by Richard Wagner (4384)\n",
      "Twenty Years After by Alexandre Dumas (4355)\n",
      "Frankenstein; Or, The Moder\n"
     ]
    }
   ],
   "source": [
    "# How does the soup object's text look like? Use .text() method and print only first 2000 characters (i.e. do not print the whole thing, it is long).\n",
    "\n",
    "print(soup.text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search in the extracted text (using regular expression) from the soup object to find the names of top 100 Ebooks (Yesterday's rank)\n",
    "\n",
    "lst_titles_temp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a starting index. It should point at the text \"Top 100 Ebooks yesterday\". Hint: Use splitlines() method of the soup.text. It splits the lines of the text of the soup object.\n",
    "\n",
    "start_idx=soup.text.splitlines().index('Top 100 EBooks yesterday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop 1-100 to add the strings of next 100 lines to this temporary list. \n",
    "\n",
    "for i in range(100):\n",
    "    lst_titles_temp.append(soup.text.splitlines()[start_idx+2+i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regular expression to extract only text from the name strings and append to an empty list\n",
    "\n",
    "lst_titles=[]\n",
    "for i in range(100):\n",
    "    id1,id2=re.match('^[a-zA-Z ]*',lst_titles_temp[i]).span()\n",
    "    lst_titles.append(lst_titles_temp[i][id1:id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top \n",
      "Top \n",
      "Top \n",
      "Top \n",
      "\n",
      "\n",
      "Top \n",
      "\n",
      "Romeo and Juliet by William Shakespeare \n",
      "A Room with a View by E\n",
      "Middlemarch by George Eliot \n",
      "Little Women\n",
      "The Enchanted April by Elizabeth Von Arnim \n",
      "Moby Dick\n",
      "The Blue Castle\n",
      "The Complete Works of William Shakespeare by William Shakespeare \n",
      "Cranford by Elizabeth Cleghorn Gaskell \n",
      "The Adventures of Ferdinand Count Fathom \n",
      "The Expedition of Humphry Clinker by T\n",
      "The Adventures of Roderick Random by T\n",
      "History of Tom Jones\n",
      "My Life \n",
      "Twenty Years After by Alexandre Dumas \n",
      "Frankenstein\n",
      "Pride and Prejudice by Jane Austen \n",
      "Superstition In All Ages \n",
      "Satan\n",
      "Alice\n",
      "The Great Gatsby by F\n",
      "The Picture of Dorian Gray by Oscar Wilde \n",
      "A Tale of Two Cities by Charles Dickens \n",
      "The alley cat\n",
      "The Yellow Wallpaper by Charlotte Perkins Gilman \n",
      "A Doll\n",
      "Ancient calendars and constellations by Emmeline M\n",
      "The Brothers Karamazov by Fyodor Dostoyevsky \n",
      "The Importance of Being Earnest\n",
      "A Modest Proposal by Jonathan Swift \n",
      "Adventures of Huckleberry Finn by Mark Twain \n",
      "The Adventures of Sherlock Holmes by Arthur Conan Doyle \n",
      "Dracula by Bram Stoker \n",
      "Metamorphosis by Franz Kafka \n",
      "Crime and Punishment by Fyodor Dostoyevsky \n",
      "The Souls of Black Folk by W\n",
      "Ulysses by James Joyce \n",
      "Grimms\n",
      "Jane Eyre\n",
      "The Slang Dictionary\n",
      "Walden\n",
      "Great Expectations by Charles Dickens \n",
      "The Prince by Niccol\n",
      "A Christmas Carol in Prose\n",
      "The Scarlet Letter by Nathaniel Hawthorne \n",
      "The Iliad by Homer \n",
      "Gambler\n",
      "The Problems of Philosophy by Bertrand Russell \n",
      "The Strange Case of Dr\n",
      "Heart of Darkness by Joseph Conrad \n",
      "Noli Me Tangere by Jos\n",
      "Winnie\n",
      "War and Peace by graf Leo Tolstoy \n",
      "The Count of Monte Cristo\n",
      "The Adventures of Tom Sawyer\n",
      "Historical record of the \n",
      "The War of the Worlds by H\n",
      "The Romance of Lust\n",
      "\n",
      "Wuthering Heights by Emily Bront\n",
      "Autobiography of Benjamin Franklin by Benjamin Franklin \n",
      "Moby Multiple Language Lists of Common Words by Grady Ward \n",
      "Dubliners by James Joyce \n",
      "Anne of Green Gables by L\n",
      "Egyptian decorative art \n",
      "Oliver Twist by Charles Dickens \n",
      "Emma by Jane Austen \n",
      "Don Quixote by Miguel de Cervantes Saavedra \n",
      "The Elements of Style by William Strunk \n",
      "The Republic by Plato \n",
      "Narrative of the Life of Frederick Douglass\n",
      "Treasure Island by Robert Louis Stevenson \n",
      "The Odyssey by Homer \n",
      "Little Women by Louisa May Alcott \n",
      "Beyond Good and Evil by Friedrich Wilhelm Nietzsche \n",
      "Beowulf\n",
      "The Interesting Narrative of the Life of Olaudah Equiano\n",
      "Tractatus Logico\n",
      "Sense and Sensibility by Jane Austen \n",
      "The Prophet by Kahlil Gibran \n",
      "The Wonderful Wizard of Oz by L\n",
      "Anna Karenina by graf Leo Tolstoy \n",
      "Gulliver\n",
      "Ang \n",
      "The great Skene mystery by Bernard Capes \n",
      "Leviathan by Thomas Hobbes \n",
      "Peter Pan by J\n",
      "Thus Spake Zarathustra\n",
      "Second Treatise of Government by John Locke \n",
      "The peaceful atom by Bernice Kohn Hunt \n",
      "The Call of the Wild by Jack London \n",
      "A Study in Scarlet by Arthur Conan Doyle \n"
     ]
    }
   ],
   "source": [
    "# Print the list of titles\n",
    "\n",
    "for l in lst_titles:\n",
    "    print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
